version: '3.8'

services:
  # CPU 환경용 서비스
  ai-server-cpu:
    build: 
      context: .
      dockerfile: Dockerfile
    image: ai-server:cpu
    container_name: ai-server-cpu
    restart: unless-stopped
    environment:
      - USE_GPU=false
    volumes:
      - ./models/downloads:/app/models/downloads
      - ./temp:/app/temp
      - ./logs:/app/logs
    ports:
      - "8000:8000"
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/system/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # GPU 환경용 서비스
  ai-server-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu  # GPU용 Dockerfile 별도 생성 가능
    image: ai-server:gpu
    container_name: ai-server-gpu
    restart: unless-stopped
    environment:
      - USE_GPU=true
      - GPU_DEVICE=0
    volumes:
      - ./models/downloads:/app/models/downloads
      - ./temp:/app/temp
      - ./logs:/app/logs
    ports:
      - "8001:8000"  # 호스트 포트를 다르게 지정하여 CPU 버전과 공존 가능
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/system/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
